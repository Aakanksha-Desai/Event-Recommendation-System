{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT TITLE</th>\n",
       "      <th>EVENT DOMAIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Times Higher Education Regional Academic Semin...</td>\n",
       "      <td>Higher Education</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Leadership Seminar by XYZ group</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Seminar on Software Applications, Applied Scie...</td>\n",
       "      <td>Other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10th Annual National Expo on Artificial Intell...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Webinar on higher education</td>\n",
       "      <td>Higher Education</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         EVENT TITLE             EVENT DOMAIN\n",
       "0  Times Higher Education Regional Academic Semin...         Higher Education\n",
       "1                    Leadership Seminar by XYZ group                     None\n",
       "2  Seminar on Software Applications, Applied Scie...                    Other\n",
       "3  10th Annual National Expo on Artificial Intell...  Artificial Intelligence\n",
       "4                        Webinar on higher education         Higher Education"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from nltk.tokenize import TweetTokenizer, RegexpTokenizer\n",
    "col = ['EVENT TITLE', 'EVENT DOMAIN']\n",
    "data = pd.read_csv(\"event_data.csv\");\n",
    "training_data = pd.DataFrame(data,columns = col)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>EVENT TITLE</th>\n",
       "      <th>EVENT DOMAIN</th>\n",
       "      <th>CONTENT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Times Higher Education Regional Academic Semin...</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>[time, higher, educ, region, academ, seminar, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Leadership Seminar by XYZ group</td>\n",
       "      <td>None</td>\n",
       "      <td>[leadership, seminar, by, xyz, group]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>Seminar on Software Applications, Applied Scie...</td>\n",
       "      <td>Other</td>\n",
       "      <td>[seminar, on, softwar, applications,, appli, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>10th Annual National Expo on Artificial Intell...</td>\n",
       "      <td>Artificial Intelligence</td>\n",
       "      <td>[10th, annual, nation, expo, on, artifici, int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>Webinar on higher education</td>\n",
       "      <td>Higher Education</td>\n",
       "      <td>[webinar, on, higher, educ]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         EVENT TITLE             EVENT DOMAIN  \\\n",
       "0  Times Higher Education Regional Academic Semin...         Higher Education   \n",
       "1                    Leadership Seminar by XYZ group                     None   \n",
       "2  Seminar on Software Applications, Applied Scie...                    Other   \n",
       "3  10th Annual National Expo on Artificial Intell...  Artificial Intelligence   \n",
       "4                        Webinar on higher education         Higher Education   \n",
       "\n",
       "                                             CONTENT  \n",
       "0  [time, higher, educ, region, academ, seminar, ...  \n",
       "1              [leadership, seminar, by, xyz, group]  \n",
       "2  [seminar, on, softwar, applications,, appli, s...  \n",
       "3  [10th, annual, nation, expo, on, artifici, int...  \n",
       "4                        [webinar, on, higher, educ]  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "\n",
    "def make_tokens(text):\n",
    "    return text.split(' ')\n",
    "        \n",
    "def process_text(text):\n",
    "    tokenized = make_tokens(text)\n",
    "    lower = [item.lower() for item in tokenized]\n",
    "    lemma = [porter.stem(x) for x in lower]\n",
    "    return lemma\n",
    "\n",
    "#preprocess data\n",
    "for line in training_data['EVENT TITLE']:\n",
    "    #print(line)\n",
    "    training_data['CONTENT'] = training_data['EVENT TITLE'].apply(process_text)\n",
    "training_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Stemming words\n",
    "from nltk.stem import PorterStemmer\n",
    "porter = PorterStemmer()\n",
    "print(porter.stem(\"application\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find word frequency in all articles\n",
    "from collections import Counter\n",
    "texts = training_data['CONTENT']\n",
    "\n",
    "def word_count(texts):\n",
    "    flat = [item for sublist in texts for item in sublist]\n",
    "    with_counts = Counter(flat)\n",
    "    top = with_counts.most_common()\n",
    "    word = [each[0] for each in top]\n",
    "    num = [each[1] for each in top]\n",
    "    return pd.DataFrame([word, num]).T\n",
    "    \n",
    "#type(texts)\n",
    "w_count = word_count(texts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['higher education', 'none', 'other', 'artificial intelligence', 'higher education', 'management', 'artificial intelligence', 'none', 'iot', 'data science', 'coding', 'networking', 'mobile application', 'coding', 'higher education', 'c++', 'none', 'none', 'none', 'other', 'iot', 'cloud computing', 'artificial intelligence', 'web development', 'none', 'none', 'coding', 'blockchain', 'other', 'development', 'none', 'mobile application', 'python', 'none', 'other', 'management', 'networking', 'python', 'java', 'web development', 'iot', 'security', 'hardware', 'cloud computing', 'mobile application', 'security', 'higher education', 'networking', 'data science', 'iot', 'artificial intelligence', 'machine learning', 'higher education', 'blockchain', 'management', 'none', 'coding', 'other', 'other', 'security', 'coding', 'coding', 'coding', 'iot', 'higher education', 'machine learning', 'artificial intelligence', 'none', 'hardware', 'finance', 'web development', 'web development', 'mobile applications', 'higher education', 'cloud computing', 'networking', 'c++', 'software architecture', 'javascript', 'other', 'blockchain', 'python', 'iot', 'data science', 'security', 'web development', 'none', 'coding', 'software architecture', 'artificial intelligence', 'machine learning', 'data science', 'mobile applications', 'blockchain', 'java', 'development processes', 'development processes', 'python', 'none', 'other', 'higher education', 'c++', 'cloud computing', 'blockchain', 'java', 'iot', 'finance', 'coding', 'web development', 'management', 'none', 'machine learning', 'c', 'none', 'cloud computing', 'cloud computing', 'other', 'none', 'mobile applications', 'mobile applications', 'higher education', 'none', 'management', 'management', 'management', 'management', 'other', 'other', 'other', 'other', 'other', 'artificial intelligence', 'hardware', 'hardware', 'security', 'security', 'management', 'security', 'security', 'mobile applications', 'mobile applications', 'iot', 'iot', 'higher education', 'higher education', 'other', 'c++', 'cloud computing', 'blockchain', 'data science', 'finance', 'security', 'networking', 'development processes', 'software architecture', 'networking', 'artificial intelligence', 'software architecture', 'development processes', 'machine learning', 'data science', 'other', 'mobile applications', 'iot', 'higher education', 'c++', 'cloud computing', 'blockchain', 'security', 'machine learning', 'machine learning', 'blockchain', 'blockchain', 'networking', 'networking', 'cloud computing', 'cloud computing', 'security', 'security', 'software architecture', 'software architecture', 'management', 'management', 'management', 'management', 'management', 'management', 'management', 'management', 'software architecture', 'blockchain', 'cloud computing', 'security', 'machine learning', 'blockchain', 'cloud computing', 'networking', 'software architecture', 'security', 'c', 'c++', 'networking', 'software architecture', 'cloud computing', 'c', 'c++', 'java', 'machine learning', 'data science', 'security', 'networking', 'cloud computing', 'management']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array(['Higher Education', 'None', 'Other', 'Artificial Intelligence',\n",
       "       'Management', 'IoT', 'Data science', 'Coding', 'networking',\n",
       "       'mobile application', 'C++', 'Cloud computing', 'Web development',\n",
       "       'none', 'Blockchain', 'Development', 'Python', 'other',\n",
       "       'Networking', 'Java', 'Web Development', 'security', 'Hardware',\n",
       "       'cloud computing', 'Data Science', 'Machine Learning', 'Security',\n",
       "       'Finance', 'Mobile Applications', 'Cloud Computing',\n",
       "       'Software Architecture', 'JavaScript', 'Development Processes',\n",
       "       'C'], dtype=object)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([11, 20, 21,  0, 16, 12,  6,  5, 19, 17,  3,  4, 25,  1,  7, 22, 13,\n",
       "       23, 10, 15,  9, 18, 24, 14,  8,  2], dtype=int64)"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_label = [item.lower() for item in training_data['EVENT DOMAIN']]\n",
    "\n",
    "print(process_label)\n",
    "#label numbers\n",
    "LE = LabelEncoder()\n",
    "training_data['label_num'] = LE.fit_transform(process_label)\n",
    "\n",
    "#display(training_data.groupby(['EVENT DOMAIN'])['EVENT TITLE'].count())\n",
    "#display(df_holdout.groupby(['label'])['content'].count())\n",
    "display(training_data['EVENT DOMAIN'].unique())\n",
    "training_data['label_num'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                           EVENT TITLE  \\\n",
      "89   Get insights into Advanced Artificial Intellig...   \n",
      "131                  Artificial Intelligence hackathon   \n",
      "156          A talk session on Artificial Intelligence   \n",
      "148         A Job opening in blockchain in our company   \n",
      "167                       A talk session on Blockchain   \n",
      "171                   A hands-on session on blockchain   \n",
      "172                   A hands-on session on blockchain   \n",
      "190  This is to notify the employees about the bloc...   \n",
      "194                    complete all blockchain courses   \n",
      "\n",
      "                EVENT DOMAIN  \\\n",
      "89   Artificial Intelligence   \n",
      "131  Artificial Intelligence   \n",
      "156  Artificial Intelligence   \n",
      "148               Blockchain   \n",
      "167               Blockchain   \n",
      "171               Blockchain   \n",
      "172               Blockchain   \n",
      "190               Blockchain   \n",
      "194               Blockchain   \n",
      "\n",
      "                                               CONTENT  label_num  \n",
      "89   [get, insight, into, advanc, artifici, intelli...          0  \n",
      "131                    [artifici, intellig, hackathon]          0  \n",
      "156         [a, talk, session, on, artifici, intellig]          0  \n",
      "148   [a, job, open, in, blockchain, in, our, compani]          1  \n",
      "167                 [a, talk, session, on, blockchain]          1  \n",
      "171             [a, hands-on, session, on, blockchain]          1  \n",
      "172             [a, hands-on, session, on, blockchain]          1  \n",
      "190  [thi, is, to, notifi, the, employe, about, the...          1  \n",
      "194                  [complet, all, blockchain, cours]          1  \n"
     ]
    }
   ],
   "source": [
    "#from gensim.models import Phrases\n",
    "\n",
    "#split training data into categories\n",
    "train_0 = training_data.loc[training_data['label_num'] == 0]\n",
    "train_1 = training_data.loc[training_data['label_num'] == 1]\n",
    "train_2 = training_data.loc[training_data['label_num'] == 2]\n",
    "train_3 = training_data.loc[training_data['label_num'] == 3]\n",
    "train_4 = training_data.loc[training_data['label_num'] == 4]\n",
    "train_5 = training_data.loc[training_data['label_num'] == 5]\n",
    "train_6 = training_data.loc[training_data['label_num'] == 6]\n",
    "train_7 = training_data.loc[training_data['label_num'] == 7]\n",
    "train_8 = training_data.loc[training_data['label_num'] == 8]\n",
    "train_9 = training_data.loc[training_data['label_num'] == 9]\n",
    "train_10 = training_data.loc[training_data['label_num'] == 10]\n",
    "train_11 = training_data.loc[training_data['label_num'] == 11]\n",
    "train_12 = training_data.loc[training_data['label_num'] == 12]\n",
    "\n",
    "#hold 5 train examples for prediction later\n",
    "train_0_hold = train_0.iloc[:5]\n",
    "train_1_hold = train_1.iloc[:5]\n",
    "train_2_hold = train_2.iloc[:5]\n",
    "train_3_hold = train_3.iloc[:5]\n",
    "train_4_hold = train_4.iloc[:5]\n",
    "train_5_hold = train_5.iloc[:5]\n",
    "train_6_hold = train_6.iloc[:5]\n",
    "train_7_hold = train_7.iloc[:5]\n",
    "train_8_hold = train_8.iloc[:5]\n",
    "train_9_hold = train_9.iloc[:5]\n",
    "train_10_hold = train_10.iloc[:5]\n",
    "train_11_hold = train_11.iloc[:5]\n",
    "train_12_hold = train_12.iloc[:5]\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "train_0 = train_0.iloc[5:]\n",
    "train_1 = train_1.iloc[5:]\n",
    "train_2 = train_2.iloc[5:]\n",
    "train_3 = train_3.iloc[5:]\n",
    "train_4 = train_4.iloc[5:]\n",
    "train_5 = train_5.iloc[5:]\n",
    "train_6 = train_6.iloc[5:]\n",
    "train_7 = train_7.iloc[5:]\n",
    "train_8 = train_8.iloc[5:]\n",
    "train_9 = train_9.iloc[5:]\n",
    "train_10 = train_10.iloc[5:]\n",
    "train_11 = train_11.iloc[5:]\n",
    "train_12 = train_12.iloc[5:]\n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat([train_0,train_1,train_2])\n",
    "print(df)\n",
    "\n",
    "#---------------------------\n",
    "\n",
    "#considering bigrams\n",
    "text_0 = train_0['CONTENT'].tolist()\n",
    "text_1 = train_1['CONTENT'].tolist()\n",
    "text_2 = train_2['CONTENT'].tolist()\n",
    "text_3 = train_3['CONTENT'].tolist()\n",
    "text_4 = train_4['CONTENT'].tolist()\n",
    "text_5 = train_5['CONTENT'].tolist()\n",
    "text_6 = train_6['CONTENT'].tolist()\n",
    "text_7 = train_7['CONTENT'].tolist()\n",
    "text_8 = train_8['CONTENT'].tolist()\n",
    "text_9 = train_9['CONTENT'].tolist()\n",
    "text_10 = train_10['CONTENT'].tolist()\n",
    "text_11 = train_11['CONTENT'].tolist()\n",
    "text_12 = train_12['CONTENT'].tolist()\n",
    "\n",
    "#text_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from nltk import word_tokenize\n",
    "from nltk.util import ngrams\n",
    "for i in range(len(text_0)):\n",
    "    token = nltk.word_tokenize(text_0[i])\n",
    "    bigram = list(ngrams(token, 2))\n",
    "    print(bigram)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "def ngrams_wrapper(sent):\n",
    "    return list(nltk.ngrams(sent, 2))\n",
    "def b_freq(text):\n",
    "    bigrams = map(ngrams_wrapper, text)\n",
    "    bigram = list(itertools.chain.from_iterable(bigrams))\n",
    "    freq_dist = nltk.FreqDist(bigram)\n",
    "    column=[\"count\"]\n",
    "    return pd.DataFrame(freq_dist,column).T\n",
    "    #prob_dist = nltk.MLEProbDist(freq_dist)\n",
    "    #number_of_bigrams = freq_dist.N()\n",
    "    #number_of_bigrams\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>announc</td>\n",
       "      <td>skill</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>skill</td>\n",
       "      <td>develop</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>develop</td>\n",
       "      <td>and</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>and</td>\n",
       "      <td>comput</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>comput</td>\n",
       "      <td>scienc</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>scienc</td>\n",
       "      <td>cours</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 count\n",
       "announc skill        1\n",
       "skill   develop      1\n",
       "develop and          1\n",
       "and     comput       1\n",
       "comput  scienc       1\n",
       "scienc  cours        1"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bigram count\n",
    "b0 = b_freq(text_0)\n",
    "b1 = b_freq(text_1)\n",
    "b2 = b_freq(text_2)\n",
    "b3 = b_freq(text_3)\n",
    "b4 = b_freq(text_4)\n",
    "b5 = b_freq(text_5)\n",
    "b6 = b_freq(text_6)\n",
    "b7 = b_freq(text_7)\n",
    "b8 = b_freq(text_8)\n",
    "b9 = b_freq(text_9)\n",
    "b10 = b_freq(text_10)\n",
    "b11 = b_freq(text_11)\n",
    "b12 = b_freq(text_12)\n",
    "#b0['artifici','intellig']\n",
    "#b_word_freq = pd.concat([b0,b1,b2,b3,b4,b5,b6,b7,b8,b9,b10,b11,b12], axis = 1)\n",
    "#b_word_freq = pd.concat([b0,b1], axis = 1)\n",
    "#column = ['0','1']\n",
    "#b_word_freq.columns = column\n",
    "#b_word_freq\n",
    "b6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(54, 122)\n",
      "(54,)\n"
     ]
    }
   ],
   "source": [
    "#make features\n",
    "text = training_data['CONTENT'].astype('str')\n",
    "\n",
    "tfidf_vectorizer = TfidfVectorizer(ngram_range=(1, 2), \n",
    "                                   min_df = 2, \n",
    "                                   max_df = .95)\n",
    "\n",
    "X = tfidf_vectorizer.fit_transform(text) #features\n",
    "y = training_data['label_num'].values #target\n",
    "\n",
    "print (X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\forest.py:245: FutureWarning: The default value of n_estimators will change from 10 in version 0.20 to 100 in 0.22.\n",
      "  \"10 in version 0.20 to 100 in 0.22.\", FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.36363636363636365"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Random Forest Classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import accuracy_score, precision_score,recall_score,f1_score\n",
    "\n",
    "#Train Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.4, shuffle = True, random_state = 3)\n",
    "\n",
    "#Fit model\n",
    "model = RandomForestClassifier(random_state=3).fit(X_train,y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:657: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed:   20.3s\n",
      "[Parallel(n_jobs=-1)]: Done 184 tasks      | elapsed:  1.5min\n",
      "[Parallel(n_jobs=-1)]: Done 434 tasks      | elapsed:  3.4min\n",
      "[Parallel(n_jobs=-1)]: Done 720 out of 720 | elapsed:  5.4min finished\n",
      "C:\\Users\\aakan\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:814: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Grid Search\n",
    "bootstrap = [True, False]\n",
    "max_depth = [10, 50, 100, None]\n",
    "max_features = ['auto', 'sqrt']\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "min_samples_split = [2, 5, 10]\n",
    "n_estimators = [800, 1400, 2000]\n",
    "random_state = [3]\n",
    "\n",
    "clf = RandomForestClassifier()\n",
    "\n",
    "params = dict(bootstrap = bootstrap,\n",
    "              max_depth = max_depth,\n",
    "              max_features = max_features,\n",
    "              min_samples_leaf = min_samples_leaf,\n",
    "              n_estimators = n_estimators,\n",
    "              random_state=random_state)\n",
    "\n",
    "gridsearch = GridSearchCV(clf,\n",
    "                          params, \n",
    "                          cv=5,\n",
    "                          verbose=1, \n",
    "                          n_jobs=-1)\n",
    "\n",
    "rf_best_model = gridsearch.fit(X, y)\n",
    "pred = rf_best_model.predict(X_test)\n",
    "accuracy = accuracy_score(y_test,pred)\n",
    "accuracy\n",
    "#rf_best_model = RandomForestClassifier(bootstrap = False,\n",
    "#                                       max_depth = 50,\n",
    "#                                       max_features = 'auto',\n",
    "#                                       min_samples_leaf = 1,\n",
    "#                                       n_estimators = 1400,\n",
    "#                                       random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with 0 sample(s) (shape=(0, 122)) while a minimum of 1 is required.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-163-cbeb463db881>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0md\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m#test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mX_unseen_tfidf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtfidf_vectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m#p = tfidf_vectorizer.fit_transform(test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;31m#p = rf_best_model.predict(z)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1679\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1680\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1681\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1682\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1683\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, X, copy)\u001b[0m\n\u001b[0;32m   1300\u001b[0m         \u001b[0mvectors\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0msparse\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1301\u001b[0m         \"\"\"\n\u001b[1;32m-> 1302\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mFLOAT_DTYPES\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1303\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0missparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1304\u001b[0m             \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcsr_matrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[0;32m    548\u001b[0m                              \u001b[1;34m\" minimum of %d is required%s.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m                              % (n_samples, array.shape, ensure_min_samples,\n\u001b[1;32m--> 550\u001b[1;33m                                 context))\n\u001b[0m\u001b[0;32m    551\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mensure_min_features\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found array with 0 sample(s) (shape=(0, 122)) while a minimum of 1 is required."
     ]
    }
   ],
   "source": [
    "#TESTING \n",
    "\n",
    "d = pd.read_csv(\"test.csv\");\n",
    "test = pd.DataFrame(d).T\n",
    "#test\n",
    "X_unseen_tfidf = tfidf_vectorizer.transform(test)\n",
    "#p = tfidf_vectorizer.fit_transform(test)\n",
    "#p = rf_best_model.predict(z)\n",
    "#p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
